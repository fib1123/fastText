{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim word2vec tutorial: http://rare-technologies.com/word2vec-tutorial/\n",
    "\n",
    "Dependencies:\n",
    "* pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure you set FT_HOME to your fastText directory root\n",
    "FT_HOME = '/Users/fib1123/Desktop/nlp/fastText/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fasttext on ../data/parsedTrimmed corpus..\n",
      "Read 272M words\n",
      "Progress: 100.0%  words/sec/thread: 41247  lr: 0.000001  loss: 1.354188  eta: 0h0m \n",
      "Train time: 5577.000000 sec\n",
      "CPU times: user 4min 15s, sys: 1min 48s, total: 6min 3s\n",
      "Wall time: 1h 34min 57s\n",
      "\n",
      "Training fasttext on ../data/parsedTrimmed corpus (without char n-grams)..\n",
      "Read 272M words\n",
      "Progress: 100.0%  words/sec/thread: 80323  lr: 0.000001  loss: 1.364331  eta: 0h0m \n",
      "Train time: 2301.000000 sec\n",
      "CPU times: user 2min 25s, sys: 1min 18s, total: 3min 43s\n",
      "Wall time: 40min 14s\n",
      "\n",
      "Training word2vec on ../data/parsedTrimmed corpus..\n",
      "CPU times: user 3h 43min 13s, sys: 1min 21s, total: 3h 44min 34s\n",
      "Wall time: 2h 57min 20s\n",
      "\n",
      "Saved gensim model as parsed_trimmed_gs.vec\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "!mkdir -p {MODELS_DIR}\n",
    "\n",
    "lr = 0.05\n",
    "dim = 100\n",
    "ws = 5\n",
    "epoch = 5\n",
    "minCount = 5\n",
    "neg = 5\n",
    "loss = 'ns'\n",
    "t = 1e-4\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "# Same values as used for fastText training above\n",
    "params = {\n",
    "    'alpha': lr,\n",
    "    'size': dim,\n",
    "    'window': ws,\n",
    "    'iter': epoch,\n",
    "    'min_count': minCount,\n",
    "    'sample': t,\n",
    "    'sg': 1,\n",
    "    'hs': 0,\n",
    "    'negative': neg\n",
    "}\n",
    "\n",
    "def train_models(corpus_file, output_name):\n",
    "    output_file = '{:s}_ft'.format(output_name)\n",
    "    if not os.path.isfile(os.path.join(MODELS_DIR, '{:s}.vec'.format(output_file))):\n",
    "        print('Training fasttext on {:s} corpus..'.format(corpus_file))\n",
    "        %time !{FT_HOME}fasttext skipgram -input {corpus_file} -output {MODELS_DIR+output_file}  -lr {lr} -dim {dim} -ws {ws} -epoch {epoch} -minCount {minCount} -neg {neg} -loss {loss} -t {t}\n",
    "    else:\n",
    "        print('\\nUsing existing model file {:s}.vec'.format(output_file))\n",
    "        \n",
    "    output_file = '{:s}_ft_no_ng'.format(output_name)\n",
    "    if not os.path.isfile(os.path.join(MODELS_DIR, '{:s}.vec'.format(output_file))):\n",
    "        print('\\nTraining fasttext on {:s} corpus (without char n-grams)..'.format(corpus_file))\n",
    "        %time !{FT_HOME}fasttext skipgram -input {corpus_file} -output {MODELS_DIR+output_file}  -lr {lr} -dim {dim} -ws {ws} -epoch {epoch} -minCount {minCount} -neg {neg} -loss {loss} -t {t} -maxn 0\n",
    "    else:\n",
    "        print('\\nUsing existing model file {:s}.vec'.format(output_file))\n",
    "        \n",
    "    output_file = '{:s}_gs'.format(output_name)\n",
    "    if not os.path.isfile(os.path.join(MODELS_DIR, '{:s}.vec'.format(output_file))):\n",
    "        print('\\nTraining word2vec on {:s} corpus..'.format(corpus_file))\n",
    "        \n",
    "        # Text8Corpus class for reading space-separated words file\n",
    "        %time gs_model = Word2Vec(Text8Corpus(corpus_file), **params); gs_model\n",
    "        # Direct local variable lookup doesn't work properly with magic statements (%time)\n",
    "        locals()['gs_model'].save_word2vec_format(os.path.join(MODELS_DIR, '{:s}.vec'.format(output_file)))\n",
    "        print('\\nSaved gensim model as {:s}.vec'.format(output_file))\n",
    "    else:\n",
    "        print('\\nUsing existing model file {:s}.vec'.format(output_file))\n",
    "\n",
    "evaluation_data = {}\n",
    "train_models('../data/parsedTrimmed', 'parsed_trimmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def print_accuracy(model, questions_file):\n",
    "    print('Evaluating...\\n')\n",
    "    acc = model.accuracy(questions_file)\n",
    "\n",
    "    sem_correct = sum((len(acc[i]['correct']) for i in range(5)))\n",
    "    sem_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5))\n",
    "    sem_acc = 100*float(sem_correct)/sem_total\n",
    "    print('\\nSemantic: {:d}/{:d}, Accuracy: {:.2f}%'.format(sem_correct, sem_total, sem_acc))\n",
    "    \n",
    "    syn_correct = sum((len(acc[i]['correct']) for i in range(5, len(acc)-1)))\n",
    "    syn_total = sum((len(acc[i]['correct']) + len(acc[i]['incorrect'])) for i in range(5,len(acc)-1))\n",
    "    syn_acc = 100*float(syn_correct)/syn_total\n",
    "    print('Syntactic: {:d}/{:d}, Accuracy: {:.2f}%\\n'.format(syn_correct, syn_total, syn_acc))\n",
    "    return (sem_acc, syn_acc)\n",
    "\n",
    "word_analogies_file = 'questions-words.txt'\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Gensim embeddings\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading Gensim embeddings')\n",
    "parsed_trimmed_gs = Word2Vec.load_word2vec_format(MODELS_DIR + 'parsed_trimmed_gs.vec')\n",
    "# print('Accuracy for Word2Vec:')\n",
    "# accuracies.append(print_accuracy(parsed_trimmed_gs, word_analogies_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FastText embeddings\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading FastText embeddings')\n",
    "parsed_trimmed_ft = Word2Vec.load_word2vec_format(MODELS_DIR + 'parsed_trimmed_ft.vec')\n",
    "# print('Accuracy for FastText (with n-grams):')\n",
    "# accuracies.append(print_accuracy(parsed_trimmed_ft, word_analogies_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText embeddings\n"
     ]
    }
   ],
   "source": [
    "print('Loading FastText embeddings')\n",
    "parsed_trimmed_ft_no_ng = Word2Vec.load_word2vec_format(MODELS_DIR + 'parsed_trimmed_ft_no_ng.vec')\n",
    "# print('Accuracy for FastText (without n-grams):')\n",
    "# accuracies.append(print_accuracy(parsed_trimmed_ft_no_ng, word_analogies_file))\n",
    "# evaluation_data['parsed_trimmed'] += [[acc[0] for acc in accuracies], [acc[1] for acc in accuracies]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'kr\\xf3lowa', 0.8168740272521973)]\n",
      "cereal\n",
      "0.787359108935\n"
     ]
    }
   ],
   "source": [
    "print parsed_trimmed_gs.most_similar(positive=['kobieta', u'król'], negative=[u'mężczyzna'], topn=1)\n",
    "print parsed_trimmed_gs.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "print parsed_trimmed_gs.similarity(u'kobieta', u'mężczyzna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'zielony', 0.8876147866249084), (u'niebieski', 0.8857795596122742), (u'\\u017c\\xf3\\u0142ty', 0.8776800036430359), (u'bia\\u0142y', 0.845734179019928), (u'czarny', 0.8080854415893555), (u'pomara\\u0144czowy', 0.7869120240211487), (u'zielono', 0.7528743743896484), (u'r\\xf3\\u017cowy', 0.7518884539604187), (u'czerwono', 0.7458332777023315), (u'b\\u0142\\u0119kitny', 0.7254201173782349)]\n"
     ]
    }
   ],
   "source": [
    "print parsed_trimmed_gs.most_similar(positive=[u'czerwony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'kr\\xf3lowa', 0.8570606708526611)]\n",
      "cereal\n",
      "0.78283114675\n"
     ]
    }
   ],
   "source": [
    "print parsed_trimmed_ft.most_similar(positive=['kobieta', u'król'], negative=[u'mężczyzna'], topn=1)\n",
    "print parsed_trimmed_ft.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "print parsed_trimmed_ft.similarity(u'kobieta', u'mężczyzna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
